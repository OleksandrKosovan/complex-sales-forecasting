{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8aa0a38",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8acd2d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1a06da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/jwsp762n00ndp1qp4rfntty40000gn/T/ipykernel_23825/3102254671.py:1: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from statsforecast.models import (\n",
    "    HistoricAverage,\n",
    "    Naive,\n",
    "    RandomWalkWithDrift,\n",
    "    SeasonalNaive,\n",
    "    WindowAverage,\n",
    "    SeasonalWindowAverage,\n",
    "    SimpleExponentialSmoothing,\n",
    "    Holt,\n",
    "    ADIDA,\n",
    "    CrostonClassic,\n",
    "    CrostonSBA,\n",
    "    IMAPA,\n",
    "    TSB,\n",
    "    MSTL,\n",
    "    Theta,\n",
    "    ARCH,\n",
    "    ARIMA,\n",
    "    AutoRegressive,\n",
    "    AutoARIMA,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af53f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsforecast import StatsForecast\n",
    "from fugue import transform\n",
    "from datasetsforecast.losses import mse, mae, rmse, mape, smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87b36e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b327922",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae77f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data/\"\n",
    "M5_FILE = \"m5-dataset.parquet.gzip\"\n",
    "FOZZY_FILE = \"fozzy-dataset.parquet.gzip\"\n",
    "FAV_FILE = \"favorita-grocery.parquet.gzip\"\n",
    "\n",
    "HORIZON = 14\n",
    "N_WINDOWS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d314351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.245182e+08\n",
       "mean     8.580000e+00\n",
       "std      2.192000e+01\n",
       "min      0.000000e+00\n",
       "25%      2.000000e+00\n",
       "50%      4.000000e+00\n",
       "75%      9.000000e+00\n",
       "max      4.414200e+04\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(os.path.join(DATA_FOLDER, FAV_FILE))\n",
    "df.y.loc[df.y >= 0].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8679cc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44142.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.y.loc[df.y >= 0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd786884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c8442bf",
   "metadata": {},
   "source": [
    "### Code base for Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c60acfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_classes_to_string(class_list):\n",
    "    class_string = '-'.join([obj.__class__.__name__ for obj in class_list])\n",
    "    return class_string\n",
    "\n",
    "\n",
    "def check_folders():\n",
    "    folders = [\n",
    "        FULL_RESULTS_PATH,\n",
    "        EVALUATION_RESULTS_PATH, \n",
    "        METRICS_RESULTS_PATH\n",
    "    ]\n",
    "    for path in folders:\n",
    "        isExist = os.path.exists(path)\n",
    "        if not isExist:\n",
    "            os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "444d34dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicModel:\n",
    "    def __init__(self, df: pd.DataFrame, models: list) -> None:\n",
    "        self.df = df\n",
    "        self.models = models\n",
    "        self.metrics = [mse, mae, rmse, mape, smape]\n",
    "    \n",
    "    def modeling(self) -> pd.DataFrame:\n",
    "        sf = StatsForecast(\n",
    "            models=self.models, \n",
    "            freq='D', \n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        result = sf.cross_validation(\n",
    "            df=self.df, \n",
    "            h=HORIZON, \n",
    "            n_windows=N_WINDOWS, \n",
    "            step_size=HORIZON, \n",
    "            level=[90]\n",
    "        )\n",
    "        return result\n",
    "    \n",
    "    def evaludate_cross_validation(self, cv_results: pd.DataFrame) -> pd.DataFrame:\n",
    "        cv_results[\"unique_id\"] = cv_results.index\n",
    "        cv_results = cv_results.reset_index(drop=True)\n",
    "\n",
    "        str_models = cv_results.loc[:, ~cv_results.columns.str.contains('unique_id|y|ds|cutoff|lo|hi')].columns\n",
    "        str_models = ','.join([f\"{model}:float\" for model in str_models])\n",
    "        \n",
    "        evaluation_df = transform(\n",
    "            cv_results.loc[:, ~cv_results.columns.str.contains('lo|hi')], \n",
    "            self.evaluate, \n",
    "            params={'metrics': self.metrics}, \n",
    "            schema=f\"unique_id:str,cutoff:str,metric:str, {str_models}\", \n",
    "            as_local=True,\n",
    "            partition={'by': ['unique_id', 'cutoff']}\n",
    "        )\n",
    "        return evaluation_df\n",
    "\n",
    "    def run(self):\n",
    "        file_name = convert_classes_to_string(self.models) + \".csv\"\n",
    "        check_folders()\n",
    "\n",
    "        print(\"Starting cross validation...\")\n",
    "        init = time()\n",
    "        result = self.modeling()\n",
    "        end = time()\n",
    "        print(f\"Cross Validation Finished In: {(end - init) / 60}\")\n",
    "\n",
    "        print(f\"Saving CV results as {file_name}...\")\n",
    "        results_path = os.path.join(FULL_RESULTS_PATH, file_name)\n",
    "        result.to_csv(results_path, index=False)\n",
    "\n",
    "        print(\"Starting Evaluation...\")\n",
    "        init = time()\n",
    "        evaluation = self.evaludate_cross_validation(result)\n",
    "        end = time()\n",
    "        print(f\"Evaluation Finished In: {(end - init) / 60}\")\n",
    "\n",
    "        print(f\"Saving evaluation as {file_name}...\")\n",
    "        evaluation.to_csv(os.path.join(EVALUATION_RESULTS_PATH, file_name), index=False)\n",
    "\n",
    "        print(\"Saving metrics...\")\n",
    "        metrics = evaluation.groupby(['metric']).mean(numeric_only=True)\n",
    "        metrics.to_csv(os.path.join(METRICS_RESULTS_PATH, file_name), index=False)\n",
    "        print(metrics)\n",
    "\n",
    "        print(\"Done!\")\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate(df: pd.DataFrame, metrics: list) -> pd.DataFrame:\n",
    "        eval_ = {}\n",
    "        models = df.loc[:, ~df.columns.str.contains('unique_id|y|ds|cutoff|lo|hi')].columns\n",
    "        for model in models:\n",
    "            eval_[model] = {}\n",
    "            for metric in metrics:\n",
    "                eval_[model][metric.__name__] = metric(df['y'], df[model])\n",
    "        eval_df = pd.DataFrame(eval_).rename_axis('metric').reset_index()\n",
    "        eval_df.insert(0, 'cutoff', df['cutoff'].iloc[0])\n",
    "        eval_df.insert(0, 'unique_id', df['unique_id'].iloc[0])\n",
    "        return eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869163b5",
   "metadata": {},
   "source": [
    "# Run Experiments - FAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f7e54d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_RESULTS_PATH = \"results/favorita-full_cv/\"\n",
    "EVALUATION_RESULTS_PATH = \"results/favorita-evaluation/\"\n",
    "METRICS_RESULTS_PATH = \"results/favorita-metrics/\"\n",
    "\n",
    "\n",
    "experiments_config = [\n",
    "\n",
    "    # HistoricAverage\n",
    "    {\n",
    "        \"experiment_name\": \"favorita-HistoricAverage\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, FAV_FILE),\n",
    "        \"models\": [HistoricAverage()],\n",
    "    },\n",
    "    \n",
    "    # Naive\n",
    "    {\n",
    "        \"experiment_name\": \"favorita-baseline\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, FAV_FILE),\n",
    "        \"models\": [Naive()],\n",
    "    },\n",
    "    \n",
    "    # RandomWalkWithDrift\n",
    "    {\n",
    "        \"experiment_name\": \"favorita-baseline\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, FAV_FILE),\n",
    "        \"models\": [RandomWalkWithDrift()],\n",
    "    },\n",
    "    \n",
    "    # SeasonalNaive\n",
    "    {\n",
    "        \"experiment_name\": \"favorita-baseline\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, FAV_FILE),\n",
    "        \"models\": [SeasonalNaive(season_length=HORIZON)],\n",
    "    },\n",
    "    \n",
    "    # WindowAverage\n",
    "    {\n",
    "        \"experiment_name\": \"favorita-baseline\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, FAV_FILE),\n",
    "        \"models\": [WindowAverage(window_size=HORIZON)],\n",
    "    },\n",
    "    \n",
    "    # SeasonalWindowAverage\n",
    "    {\n",
    "        \"experiment_name\": \"favorita-baseline\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, FAV_FILE),\n",
    "        \"models\": [SeasonalWindowAverage(season_length=HORIZON, window_size=HORIZON)],\n",
    "    },\n",
    "\n",
    "    # SimpleExponentialSmoothing\n",
    "    {\n",
    "        \"experiment_name\": \"favorita-exponential-smoothing\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, FAV_FILE),\n",
    "        \"models\": [SimpleExponentialSmoothing(alpha=0.3)],\n",
    "    },\n",
    "    \n",
    "    # Holt\n",
    "    {\n",
    "        \"experiment_name\": \"favorita-exponential-smoothing\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, FAV_FILE),\n",
    "        \"models\": [Holt()],\n",
    "    },\n",
    "\n",
    "    # ADIDA\n",
    "    {\n",
    "        \"experiment_name\": \"favorita-sparse-intermittent\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, FAV_FILE),\n",
    "        \"models\": [ADIDA()],\n",
    "    },\n",
    "    \n",
    "    # CrostonClassic\n",
    "    {\n",
    "        \"experiment_name\": \"favorita-sparse-intermittent\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, FAV_FILE),\n",
    "        \"models\": [CrostonClassic()],\n",
    "    },\n",
    "    \n",
    "    # CrostonSBA\n",
    "    {\n",
    "        \"experiment_name\": \"favorita-sparse-intermittent\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, FAV_FILE),\n",
    "        \"models\": [CrostonSBA()],\n",
    "    },\n",
    "    \n",
    "    # IMAPA\n",
    "    {\n",
    "        \"experiment_name\": \"favorita-sparse-intermittent\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, FAV_FILE),\n",
    "        \"models\": [IMAPA()],\n",
    "    },\n",
    "    \n",
    "    # TSB\n",
    "    {\n",
    "        \"experiment_name\": \"favorita-sparse-intermittent\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, FAV_FILE),\n",
    "        \"models\": [TSB(alpha_d=0.2, alpha_p=0.2)],\n",
    "    },\n",
    "\n",
    "    # MSTL\n",
    "    {\n",
    "        \"experiment_name\": \"favorita-other\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, FAV_FILE),\n",
    "        \"models\": [MSTL(season_length=HORIZON)],\n",
    "    },\n",
    "    \n",
    "    # Theta\n",
    "    {\n",
    "        \"experiment_name\": \"favorita-other\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, FAV_FILE),\n",
    "        \"models\": [Theta()],\n",
    "    },\n",
    "    \n",
    "    # ARCH\n",
    "    {\n",
    "        \"experiment_name\": \"favorita-other\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, FAV_FILE),\n",
    "        \"models\": [ARCH()],\n",
    "    },\n",
    "\n",
    "    # ARIMA\n",
    "    {\n",
    "        \"experiment_name\": \"favorita-arima\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, FAV_FILE),\n",
    "        \"models\": [ARIMA()],\n",
    "    },\n",
    "    \n",
    "    # AutoRegressive\n",
    "    {\n",
    "        \"experiment_name\": \"favorita-ar\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, FAV_FILE),\n",
    "        \"models\": [AutoRegressive(lags=HORIZON)],\n",
    "    },\n",
    "\n",
    "    # AutoARIMA\n",
    "    {\n",
    "        \"experiment_name\": \"favorita-AutoARIMA\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, FAV_FILE),\n",
    "        \"models\": [AutoARIMA()],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16622448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experiment_name': 'favorita-ar', 'data': 'data/favorita-grocery.parquet.gzip', 'models': [AutoRegressive]}\n",
      "{'experiment_name': 'favorita-AutoARIMA', 'data': 'data/favorita-grocery.parquet.gzip', 'models': [AutoARIMA]}\n"
     ]
    }
   ],
   "source": [
    "for config in experiments_config[17:]:\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20bd540b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experiment_name': 'favorita-ar', 'data': 'data/favorita-grocery.parquet.gzip', 'models': [AutoRegressive]} \n",
      "\n",
      "Starting cross validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oleksandr/opt/anaconda3/envs/phd/lib/python3.10/site-packages/statsforecast/arima.py:680: RuntimeWarning: overflow encountered in subtract\n",
      "  x -= np.dot(xreg, par[narma + np.arange(ncxreg)])\n",
      "/Users/oleksandr/opt/anaconda3/envs/phd/lib/python3.10/site-packages/statsforecast/arima.py:680: RuntimeWarning: overflow encountered in subtract\n",
      "  x -= np.dot(xreg, par[narma + np.arange(ncxreg)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Finished In: 420.8960395296415\n",
      "Saving CV results as AutoRegressive.csv...\n",
      "Starting Evaluation...\n",
      "Evaluation Finished In: 9.75882534980774\n",
      "Saving evaluation as AutoRegressive.csv...\n",
      "Saving metrics...\n",
      "        AutoRegressive\n",
      "metric                \n",
      "mae       1.103118e+02\n",
      "mape      1.751388e+03\n",
      "mse       4.286200e+09\n",
      "rmse      1.724310e+02\n",
      "smape     5.388262e+01\n",
      "Done!\n",
      "{'experiment_name': 'favorita-AutoARIMA', 'data': 'data/favorita-grocery.parquet.gzip', 'models': [AutoARIMA]} \n",
      "\n",
      "Starting cross validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oleksandr/opt/anaconda3/envs/phd/lib/python3.10/site-packages/statsforecast/arima.py:1255: RuntimeWarning: overflow encountered in square\n",
      "  fit[\"sigma2\"] = np.nansum(fit[\"residuals\"] ** 2) / (nstar - npar + 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Finished In: 198.28100754817328\n",
      "Saving CV results as AutoARIMA.csv...\n",
      "Starting Evaluation...\n",
      "Evaluation Finished In: 9.761488183339436\n",
      "Saving evaluation as AutoARIMA.csv...\n",
      "Saving metrics...\n",
      "         AutoARIMA\n",
      "metric            \n",
      "mae       3.713717\n",
      "mape     88.944397\n",
      "mse     376.815491\n",
      "rmse      4.805626\n",
      "smape    55.093552\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for config in experiments_config[17:]:\n",
    "    print(config, \"\\n\")\n",
    "    \n",
    "    df = pd.read_parquet(config[\"data\"])\n",
    "\n",
    "    try:\n",
    "        inst = ClassicModel(df, config[\"models\"])\n",
    "        inst.run()\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {config['experiment_name']}\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71e5c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760ae8ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c362c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235cda4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfba3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be4aff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PhD env",
   "language": "python",
   "name": "phd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
