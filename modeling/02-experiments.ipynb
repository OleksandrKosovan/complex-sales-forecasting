{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8aa0a38",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8acd2d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1a06da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/jwsp762n00ndp1qp4rfntty40000gn/T/ipykernel_42719/3102254671.py:1: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from statsforecast.models import (\n",
    "    HistoricAverage,\n",
    "    Naive,\n",
    "    RandomWalkWithDrift,\n",
    "    SeasonalNaive,\n",
    "    WindowAverage,\n",
    "    SeasonalWindowAverage,\n",
    "    SimpleExponentialSmoothing,\n",
    "    Holt,\n",
    "    ADIDA,\n",
    "    CrostonClassic,\n",
    "    CrostonSBA,\n",
    "    IMAPA,\n",
    "    TSB,\n",
    "    MSTL,\n",
    "    Theta,\n",
    "    ARCH,\n",
    "    ARIMA,\n",
    "    AutoRegressive,\n",
    "    AutoARIMA,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af53f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsforecast import StatsForecast\n",
    "from fugue import transform\n",
    "from datasetsforecast.losses import mse, mae, rmse, mape, smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87b36e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b327922",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae77f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data/\"\n",
    "M5_FILE = \"m5-dataset.parquet.gzip\"\n",
    "# FOZZY_FILE = \"fozzy-dataset.parquet.gzip\"\n",
    "\n",
    "HORIZON = 14\n",
    "N_WINDOWS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfa55f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_RESULTS_PATH = \"results/full_cv/\"\n",
    "EVALUATION_RESULTS_PATH = \"results/evaluation/\"\n",
    "METRICS_RESULTS_PATH = \"results/metrics/\"\n",
    "\n",
    "experiments_config = [\n",
    "\n",
    "    # Baseline Models\n",
    "    {\n",
    "        \"experiment_name\": \"m5-baseline\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, M5_FILE),\n",
    "        \"models\": [\n",
    "            HistoricAverage(),\n",
    "            Naive(),\n",
    "            RandomWalkWithDrift(),\n",
    "            SeasonalNaive(season_length=HORIZON),\n",
    "            WindowAverage(window_size=HORIZON),\n",
    "            SeasonalWindowAverage(season_length=HORIZON, window_size=HORIZON),\n",
    "        ],\n",
    "    },\n",
    "\n",
    "    # Exponential Smoothing Models\n",
    "    {\n",
    "        \"experiment_name\": \"m5-exponential-smoothing\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, M5_FILE),\n",
    "        \"models\": [\n",
    "            SimpleExponentialSmoothing(alpha=0.3),\n",
    "            Holt(),\n",
    "        ],\n",
    "    },\n",
    "\n",
    "    # Sparse or Intermittent Models\n",
    "    {\n",
    "        \"experiment_name\": \"m5-sparse-intermittent\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, M5_FILE),\n",
    "        \"models\": [\n",
    "            ADIDA(),\n",
    "            CrostonClassic(),\n",
    "            CrostonSBA(),\n",
    "            IMAPA(),\n",
    "            TSB(alpha_d=0.2, alpha_p=0.2)\n",
    "        ],\n",
    "    },\n",
    "\n",
    "    # Other Models\n",
    "    {\n",
    "        \"experiment_name\": \"m5-other\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, M5_FILE),\n",
    "        \"models\": [\n",
    "            MSTL(season_length=HORIZON),\n",
    "            Theta(),\n",
    "            ARCH()\n",
    "        ],\n",
    "    },\n",
    "\n",
    "    # AR and ARIMA\n",
    "    {\n",
    "        \"experiment_name\": \"m5-ar-arima\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, M5_FILE),\n",
    "        \"models\": [\n",
    "            ARIMA(),\n",
    "            AutoRegressive(lags=HORIZON)\n",
    "        ],\n",
    "    },\n",
    "\n",
    "    # AR and ARIMA\n",
    "    {\n",
    "        \"experiment_name\": \"m5-AutoARIMA\",\n",
    "        \"data\": os.path.join(DATA_FOLDER, M5_FILE),\n",
    "        \"models\": [\n",
    "            AutoARIMA()\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8442bf",
   "metadata": {},
   "source": [
    "### Code base for Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c60acfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_classes_to_string(class_list):\n",
    "    class_string = '-'.join([obj.__class__.__name__ for obj in class_list])\n",
    "    return class_string\n",
    "\n",
    "\n",
    "def check_folders():\n",
    "    folders = [\n",
    "        FULL_RESULTS_PATH,\n",
    "        EVALUATION_RESULTS_PATH, \n",
    "        METRICS_RESULTS_PATH\n",
    "    ]\n",
    "    for path in folders:\n",
    "        isExist = os.path.exists(path)\n",
    "        if not isExist:\n",
    "            os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "444d34dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicModel:\n",
    "    def __init__(self, df: pd.DataFrame, models: list) -> None:\n",
    "        self.df = df\n",
    "        self.models = models\n",
    "        self.metrics = [mse, mae, rmse, mape, smape]\n",
    "    \n",
    "    def modeling(self) -> pd.DataFrame:\n",
    "        sf = StatsForecast(\n",
    "            models=self.models, \n",
    "            freq='D', \n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        result = sf.cross_validation(\n",
    "            df=self.df, \n",
    "            h=HORIZON, \n",
    "            n_windows=N_WINDOWS, \n",
    "            step_size=HORIZON, \n",
    "            level=[90]\n",
    "        )\n",
    "        return result\n",
    "    \n",
    "    def evaludate_cross_validation(self, cv_results: pd.DataFrame) -> pd.DataFrame:\n",
    "        cv_results[\"unique_id\"] = cv_results.index\n",
    "        cv_results = cv_results.reset_index(drop=True)\n",
    "\n",
    "        str_models = cv_results.loc[:, ~cv_results.columns.str.contains('unique_id|y|ds|cutoff|lo|hi')].columns\n",
    "        str_models = ','.join([f\"{model}:float\" for model in str_models])\n",
    "        \n",
    "        evaluation_df = transform(\n",
    "            cv_results.loc[:, ~cv_results.columns.str.contains('lo|hi')], \n",
    "            self.evaluate, \n",
    "            params={'metrics': self.metrics}, \n",
    "            schema=f\"unique_id:str,cutoff:str,metric:str, {str_models}\", \n",
    "            as_local=True,\n",
    "            partition={'by': ['unique_id', 'cutoff']}\n",
    "        )\n",
    "        return evaluation_df\n",
    "\n",
    "    def run(self):\n",
    "        file_name = convert_classes_to_string(self.models) + \".csv\"\n",
    "        check_folders()\n",
    "\n",
    "        print(\"Starting cross validation...\")\n",
    "        init = time()\n",
    "        result = self.modeling()\n",
    "        end = time()\n",
    "        print(f\"Cross Validation Finished In: {(end - init) / 60}\")\n",
    "\n",
    "        print(f\"Saving CV results as {file_name}...\")\n",
    "        results_path = os.path.join(FULL_RESULTS_PATH, file_name)\n",
    "        result.to_csv(results_path, index=False)\n",
    "\n",
    "        print(\"Starting Evaluation...\")\n",
    "        init = time()\n",
    "        evaluation = self.evaludate_cross_validation(result)\n",
    "        end = time()\n",
    "        print(f\"Evaluation Finished In: {(end - init) / 60}\")\n",
    "\n",
    "        print(f\"Saving evaluation as {file_name}...\")\n",
    "        evaluation.to_csv(os.path.join(EVALUATION_RESULTS_PATH, file_name), index=False)\n",
    "\n",
    "        print(\"Saving metrics...\")\n",
    "        metrics = evaluation.groupby(['metric']).mean(numeric_only=True)\n",
    "        metrics.to_csv(os.path.join(METRICS_RESULTS_PATH, file_name), index=False)\n",
    "        print(metrics)\n",
    "\n",
    "        print(\"Done!\")\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate(df: pd.DataFrame, metrics: list) -> pd.DataFrame:\n",
    "        eval_ = {}\n",
    "        models = df.loc[:, ~df.columns.str.contains('unique_id|y|ds|cutoff|lo|hi')].columns\n",
    "        for model in models:\n",
    "            eval_[model] = {}\n",
    "            for metric in metrics:\n",
    "                eval_[model][metric.__name__] = metric(df['y'], df[model])\n",
    "        eval_df = pd.DataFrame(eval_).rename_axis('metric').reset_index()\n",
    "        eval_df.insert(0, 'cutoff', df['cutoff'].iloc[0])\n",
    "        eval_df.insert(0, 'unique_id', df['unique_id'].iloc[0])\n",
    "        return eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250bce54",
   "metadata": {},
   "source": [
    "### Run Experiments - M5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa6198a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experiment_name': 'm5-baseline', 'data': 'data/m5-dataset.parquet.gzip', 'models': [HistoricAverage, Naive, RWD, SeasonalNaive, WindowAverage, SeasWA]} \n",
      "\n",
      "Starting cross validation...\n",
      "Cross Validation Finished In: 0.4957402507464091\n",
      "Saving CV results as HistoricAverage-Naive-RandomWalkWithDrift-SeasonalNaive-WindowAverage-SeasonalWindowAverage.csv...\n",
      "Starting Evaluation...\n",
      "Evaluation Finished In: 18.154188819726308\n",
      "Saving evaluation as HistoricAverage-Naive-RandomWalkWithDrift-SeasonalNaive-WindowAverage-SeasonalWindowAverage.csv...\n",
      "Saving metrics...\n",
      "        HistoricAverage      Naive         RWD  SeasonalNaive  WindowAverage  \\\n",
      "metric                                                                         \n",
      "mae            1.150872   1.345297    1.353526       1.250565       1.031242   \n",
      "mape          27.010265  40.528393   40.771969      38.057278      26.771885   \n",
      "mse            6.036355   8.400986    8.446992       7.541581       4.536812   \n",
      "rmse           1.435070   1.720832    1.726687       1.749777       1.312924   \n",
      "smape        142.423172  84.071693  157.073135      82.295830     126.161217   \n",
      "\n",
      "            SeasWA  \n",
      "metric              \n",
      "mae       1.072436  \n",
      "mape     27.349192  \n",
      "mse       5.015110  \n",
      "rmse      1.376366  \n",
      "smape   132.071579  \n",
      "Done!\n",
      "{'experiment_name': 'm5-exponential-smoothing', 'data': 'data/m5-dataset.parquet.gzip', 'models': [SES, Holt]} \n",
      "\n",
      "Starting cross validation...\n",
      "Cross Validation Finished In: 18.370328017075856\n",
      "Saving CV results as SimpleExponentialSmoothing-Holt.csv...\n",
      "Starting Evaluation...\n",
      "Evaluation Finished In: 8.280398285388946\n",
      "Saving evaluation as SimpleExponentialSmoothing-Holt.csv...\n",
      "Saving metrics...\n",
      "               SES        Holt\n",
      "metric                        \n",
      "mae       1.087095    1.038411\n",
      "mape     29.250298   26.868515\n",
      "mse       4.988080    4.725869\n",
      "rmse      1.374435    1.311249\n",
      "smape   142.377792  140.677277\n",
      "Done!\n",
      "{'experiment_name': 'm5-sparse-intermittent', 'data': 'data/m5-dataset.parquet.gzip', 'models': [ADIDA, CrostonClassic, CrostonSBA, IMAPA, TSB]} \n",
      "\n",
      "Starting cross validation...\n",
      "Cross Validation Finished In: 1.6327399333318076\n",
      "Saving CV results as ADIDA-CrostonClassic-CrostonSBA-IMAPA-TSB.csv...\n",
      "Starting Evaluation...\n",
      "Evaluation Finished In: 15.203570334116618\n",
      "Saving evaluation as ADIDA-CrostonClassic-CrostonSBA-IMAPA-TSB.csv...\n",
      "Saving metrics...\n",
      "             ADIDA  CrostonClassic  CrostonSBA       IMAPA         TSB\n",
      "metric                                                                \n",
      "mae       1.033333        1.077581    1.062102    1.035718    1.049494\n",
      "mape     26.774540       26.484591   26.184174   26.847736   27.460527\n",
      "mse       4.619286        4.779842    4.728084    4.625645    4.629081\n",
      "rmse      1.306135        1.346552    1.339174    1.308334    1.327559\n",
      "smape   140.619705      140.636902  141.386597  140.585358  141.002365\n",
      "Done!\n",
      "{'experiment_name': 'm5-other', 'data': 'data/m5-dataset.parquet.gzip', 'models': [MSTL, Theta, ARCH(1)]} \n",
      "\n",
      "Starting cross validation...\n",
      "Cross Validation Finished In: 77.84994231859842\n",
      "Saving CV results as MSTL-Theta-ARCH.csv...\n",
      "Starting Evaluation...\n",
      "Evaluation Finished In: 11.711616333325704\n",
      "Saving evaluation as MSTL-Theta-ARCH.csv...\n",
      "Saving metrics...\n",
      "              MSTL       Theta     ARCH(1)\n",
      "metric                                    \n",
      "mae       1.156551    1.043163    2.517262\n",
      "mape     32.450371   27.006792   67.993332\n",
      "mse       5.702271    4.738752  110.727806\n",
      "rmse      1.506866    1.317440    3.073506\n",
      "smape   148.834534  140.736816  178.164734\n",
      "Done!\n",
      "{'experiment_name': 'm5-ar-arima', 'data': 'data/m5-dataset.parquet.gzip', 'models': [ARIMA, AutoRegressive]} \n",
      "\n",
      "Starting cross validation...\n",
      "Cross Validation Finished In: 433.98839943011603\n",
      "Saving CV results as ARIMA-AutoRegressive.csv...\n",
      "Starting Evaluation...\n",
      "Evaluation Finished In: 8.665697765350341\n",
      "Saving evaluation as ARIMA-AutoRegressive.csv...\n",
      "Saving metrics...\n",
      "             ARIMA  AutoRegressive\n",
      "metric                            \n",
      "mae       1.150873        1.035746\n",
      "mape     27.010149       25.977579\n",
      "mse       6.036349        4.308738\n",
      "rmse      1.435069        1.312324\n",
      "smape   142.422943      140.404236\n",
      "Done!\n",
      "{'experiment_name': 'm5-AutoARIMA', 'data': 'data/m5-dataset.parquet.gzip', 'models': [AutoARIMA]} \n",
      "\n",
      "Starting cross validation...\n"
     ]
    }
   ],
   "source": [
    "for config in experiments_config:\n",
    "    print(config, \"\\n\")\n",
    "    \n",
    "    df = pd.read_parquet(config[\"data\"])\n",
    "\n",
    "    inst = ClassicModel(df, config[\"models\"])\n",
    "    inst.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deeba19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9098ab11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment_name': 'm5-AutoARIMA',\n",
       " 'data': 'data/m5-dataset.parquet.gzip',\n",
       " 'models': [AutoARIMA]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = experiments_config[5]\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813c352f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cross validation...\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(config[\"data\"])\n",
    "\n",
    "inst = ClassicModel(df, config[\"models\"])\n",
    "inst.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9924fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c684087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323222c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be4aff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PhD env",
   "language": "python",
   "name": "phd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
